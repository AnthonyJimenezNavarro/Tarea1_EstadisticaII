---
title: "Tarea 1 - CA0307: Estadística Actuarial II"
author:
- Anthony Mauricio Jiménez Navarro | C24067
- Henri Gerard Gabert Hidalgo | B93096
- Juan Pablo Morgan Sandí | C15319
output:
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: true
  pdf_document:
    toc: true
date: "2024-09-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

Se cargan los paquetes necesarios
```{r message=FALSE, warning=FALSE}
library(univariateML)
library(rriskDistributions)
library("fGarch")
library(dplyr)
library(ggplot2)
library(ks)
library(boot)
```

Se carga la base de datos
```{r}
base_salarios <- read.csv("BaseSalarios.csv", header = TRUE, sep = ";", stringsAsFactors = FALSE)
base_salarios <- base_salarios[ , !(names(base_salarios) %in% c("X"))]
base_salarios <- na.omit(base_salarios)

# Eliminar cualquier símbolo no numérico (excepto comas y puntos)
base_salarios$U..Salario <- gsub("[^0-9,\\.]", "", base_salarios$U..Salario)

# Eliminar espacios en blanco
base_salarios$U..Salario <- trimws(base_salarios$U..Salario)

# Reemplazar comas decimales por puntos decimales
base_salarios$U..Salario <- gsub(",", ".", base_salarios$U..Salario)

# Convertir a numérico
base_salarios$U..Salario <- as.numeric(base_salarios$U..Salario)

```

# Ejercicio 1

## 1
```{r}
base_salarios$Nivel <- ifelse(base_salarios$Coutas < 150, 1, 2)
```

## 2
```{r}
analisis_descriptivo <- base_salarios %>%
  group_by(Nivel) %>%
  summarise(
    Promedio_Salarios = mean(`U..Salario`, na.rm = TRUE),
    Varianza_Salarios = var(`U..Salario`, na.rm = TRUE),
    Cantidad_Salarios = n(),
    Max_Salarios = max(`U..Salario`, na.rm = TRUE),
    Min_Salarios = min(`U..Salario`, na.rm = TRUE),
    
    # Para Sexo, podemos contar la cantidad de hombres y mujeres por Nivel
    Cantidad_Hombres = sum(Sexo == 1, na.rm = TRUE),
    Cantidad_Mujeres = sum(Sexo == 2, na.rm = TRUE)
  )
```

## 3

Un boxplot es una representación gráfica que resume la distribución de un conjunto de datos, mostrando en el, los cuartiles, mínimo y máximo, siendo la caja el rango intercuartilico es decir la diferencia entre el Q3 y Q1, la línea dentro de la caja el Q2 es decir la mediana y las líneas que se alargan de las cajas, son conocidos como bigotes se extienden al máximo y mínimo, lo que esté por fuera son outliers. Por lo que los considero utiles por 3 motivos, 1. nos permiten ver más o menos una distribución de los datos, 2. es fácil ver o comparar esa distribución por grupos y 3. la fácil detección de outliers.

## 4
```{r}
ggplot(base_salarios, aes(x = factor(Nivel), y = `U..Salario`, fill = factor(Nivel))) +
  geom_boxplot() +
  labs(
    x = "Nivel",
    y = "Salario",
    title = "Comparación de Salarios entre Niveles"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("#B63191", "skyblue")) +
  theme(legend.position = "none")
```

## 5

Al observar el gráfico, me gustaría decir que entre más cuotas ha aportado, más salario se percibe, pero no es cierto. Aunque, si lo vemos desde otro punto de vista, la mediana del grupo 2 es mayor. El promedio que nos da el análisis descriptivo es más alto, y tanto el valor máximo como el mínimo son superiores en el grupo 2. Incluso, la caja de aquellos que han pagado más de 150 cuotas se ubica más arriba, salarialmente hablando, que los que han pagado menos de 150, esto significa que el 75% de las personas del nivel 2 perciben un salario mayor que el 75% de las personas del nivel 1. En general, se puede concluir que el grupo que ha aportado más cuotas tiene una percepción salarial superior.

Además, gracias al boxplot también se pueden observar varios outliers en ambos grupos, pero la cantidad es mayor en el grupo 2.


## 6

Vamos a realizar una prueba de hipótesis para comparar las medias salariales de aquellas personas que han aportado menos de 150 cuotas y de aquellos que han aportado más de 150.
```{r}
# Filtrar los salarios según el nivel
salarios_nivel_1 <- base_salarios$U..Salario[base_salarios$Nivel == 1]
salarios_nivel_2 <- base_salarios$U..Salario[base_salarios$Nivel == 2]

# Realizar la prueba t
resultado_t_test <- t.test(salarios_nivel_1, salarios_nivel_2)

# Mostrar resultados de la prueba
print(resultado_t_test)
```
Al obtener un p-valor de 2.2e-16 podemos concluir que el promedio salarial de los grupos es completamente diferente.

# Ejercicio 2

## 1

```{r}
# Creamos el histograma con la columna Cuotas-
hist(base_salarios$Coutas, main = "Histograma de la Cuotas", freq = F, xlab = "Cuotas", ylab = "Densidad")
# Le añadimos la línea que representa la densidad.
lines(density(base_salarios$Coutas), col = "aquamarine4", lwd = 2)
```

## 2

Ahora, graficaremos, para cada kernel estudiado, la densidad de la variable cuotas.

### Biweight

```{r}
# Graficamos con Kernel de Silverman.
plot(density(base_salarios$Coutas, bw = "nrd0",  kernel = "biweight"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Bandwidth de Silverman", xlab = "Cuotas", ylab = "Densidad")
```


Respecto al "nrd0", fue tomado de (Bandwidth Function - RDocumentation, s.f.) 

### Gaussiana

```{r}
# Graficamos con Kernel Gaussiano.
plot(density(base_salarios$Coutas, kernel = "gaussian"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Gaussiano", xlab = "Cuotas", ylab = "Densidad")
```

### Epanechnikov
```{r}
# Graficamos con Kernel de Epanechnikov.
plot(density(base_salarios$Coutas, kernel = "epanechnikov"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Epanechnikov", xlab = "Cuotas", ylab = "Densidad")
```

### Coseno
```{r}
# Graficamos con Kernel Coseno.
plot(density(base_salarios$Coutas, kernel = "cosine"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Coseno", xlab = "Cuotas", ylab = "Densidad")
```

### Uniforme
```{r}
# Graficamos con Kernel Uniforme.
plot(density(base_salarios$Coutas, kernel = "rectangular"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Rectangular", xlab = "Cuotas", ylab = "Densidad")
```

### Triangular
```{r}
# Graficamos con Kernel Triangular.
plot(density(base_salarios$Coutas, kernel = "triangular"), col = "aquamarine4", lwd = 2, main = "Densidad de las Cuotas según kernel Triangular", xlab = "Cuotas", ylab = "Densidad")
```

## 3

Creamos un vector con los nombres de todos los kernels disponibles para la función density.

```{r}
(kernels <- eval(formals(density.default)$kernel))
```

Ahora, generamos el gráfico con todos a la vez, para apreciar las diferencias entre cada uno de estos.

```{r}
# primero llamamos el kernel normal como base para el gráfico.
plot(density(base_salarios$Coutas, kernel = "gaussian"), col = "black", lwd = 2, main = "Densidad de las Cuotas según kernel", xlab = "Cuotas", ylab = "Densidad")

# creamos un ciclo for, para evaluar cada kernel, y añadirlo al gráfico.
for(i in 2:length(kernels))
lines(density(base_salarios$Coutas, kernel = kernels[i]), col = i, lwd = 2)
legend("topright", legend = kernels, col = seq(kernels), lty = 1,lwd = 2,cex = 0.5)
```

# Ejercicio 3

## 1

El Criterio de Información de Akaike (AIC) evalúa la calidad de un modelo ajustado considerando tanto la cantidad de parámetros como la calidad del ajuste. La fórmula del AIC es:

AIC = 2K - 2ln(L)

Donde k representa el número de parámetros del modelo y L es la función de máxima verosimilitud del modelo. El AIC penaliza los modelos más complejos, es decir, aquellos con más parámetros, para reducir el riesgo de sobreajuste. Se considera que el mejor modelo es aquel con el valor de AIC más bajo.

## 2


```{r}
base_salarios <- read.csv("BaseSalarios.csv", header = TRUE, sep = ";", stringsAsFactors = FALSE)
base_salarios <- base_salarios[, !names(base_salarios) %in% "X"]
base_salarios <- na.omit(base_salarios)

```

```{r}
valores <- model_select(base_salarios$Coutas)
print(valores)
mean_model <- as.numeric(valores["mean"])
sd_model <- as.numeric(valores["sd"])
nu_model <- as.numeric(valores["nu"])
xi_model <- as.numeric(valores["xi"])

L <- sum(dsged(base_salarios$Coutas, mean = mean_model, sd = sd_model, nu = nu_model, xi = xi_model, log = TRUE))
k <- 4
AIC_1 <- -2 * L + 2 * k

exp <- mlexp(base_salarios$Coutas)
gamma <- mlgamma(base_salarios$Coutas)
lognormal <- mllnorm(base_salarios$Coutas)
weibull <- mlweibull(base_salarios$Coutas)
loggamma <- mllgamma(base_salarios$Coutas+1)
uniform <- mlunif(base_salarios$Coutas)

AIC_Calculados <- data.frame(
  DistribuCION = c("Model_Select", "Exponential", "Gamma", "Lognormal", "Weibull", "Loggamma", "Uniform"),
  AIC = c(AIC_1, 
          AIC(exp), 
          AIC(gamma), 
          AIC(lognormal),
          AIC(weibull), 
          AIC(loggamma), 
          AIC(uniform))
)

print(AIC_Calculados)
```

De la tabla se logra observar que el menor valor de AIC corresponde a la distribución Weibull, de forma que siguiendo el Criterio de Información de Akaike es elije este.

## 3

```{r}
ajuste_risk <- fit.cont(base_salarios$Coutas)
print(ajuste_risk)
```

## 4

Del punto 2 se observa que la distribución que mejor se ajuste corresponde a Weibull, pero del punto 3, al utilizar fit.cont(), podemos observar que la distribución Gompertz, presenta un valor de AIC menor al resto, de forma que resulta la más adecuada, pero ya que esta no formaba parte del inciso, se decide tomar la segunda mejor que corresponde a Weibull.

## 5

```{r}
bootstrap <- bootstrapml(weibull, reps = 1000, map = function(x) c(mean = mean(x), sd = sd(x)))

IC_mean <- c(bootstrap[1,1], bootstrap[1,2])
IC_sd <- c(bootstrap[2,1], bootstrap[2,2])

print(IC_mean)
print(IC_sd)
```


# Ejercicio 4

## 1
Del paquete ks de r, la función kde realiza una estimación de densidad mediante kernel, con bases de 1 a 6 variables, por lo que su la función nos facilita el estimar y visualizar la densidad de probabilidad de un conjunto de datos de manera no paramétrica, permitiendonos obtener una representación suave y continua de su distribución.

```{r}
densidad_kde <- kde(base_salarios$Coutas)

plot(densidad_kde, xlab = "Cuotas",ylab = "Densidad",main = "Estimación de Densidad de Cuotas")
```


## 2
Del paquete boot de r, la función boot.ci calcula 5 intervalos de confianza distintos, no parametricos (la aproximación normal de primer orden, el intervalo bootstrap básico, el intervalo bootstrap estudentizado, el intervalo de percentil bootstrap y el intervalo de percentil bootstrap ajustado (BCa)), basados en el método de bootstrap.



## 3

```{r}
# Función para calcular la media


# Bootstrap de la media de Cuotas
result <- boot(data = base_salarios$Coutas,  statistic=function(y,indices) exp(mean(y[indices])) , R = 1000)

# Media original
media_original <- result$t0

# Media bootstrap (t)
media_bootstrap <- result$t

plot(result)

# Resultados
cat("Media original:", media_original, "\n")
cat("Media bootstrap:", media_bootstrap, "\n")

# Histograma de las medias bootstrap
hist(result$t, 
     main = "Histograma de Medias Bootstrap",
     xlab = "Media Bootstrap de Cuotas",
     col = "lightblue",
     border = "black")

```




# Referencias
Angelo Canty(2024) Package ‘boot’: https://cran.r-project.org/web/packages/boot/boot.pdf

bandwidth function - RDocumentation. (s.f.). https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/bandwidth

JMP Statistical Discovery LLC (2024) Diagrama de caja: https://www.jmp.com/es_es/statistics-knowledge-portal/exploratory-data-analysis/box-plot.html

Tarn Duong(2024) Package ‘ks’: https://cran.r-project.org/web/packages/ks/ks.pdf




